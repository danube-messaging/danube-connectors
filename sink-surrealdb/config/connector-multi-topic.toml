# SurrealDB Sink Connector - Multi-Topic Configuration Example
#
# This example shows how to consume from multiple Danube topics with different
# schema types and route each to different SurrealDB tables.

connector_name = "surrealdb-sink-multi"
danube_service_url = "http://localhost:6650"

[surrealdb]
url = "ws://localhost:8000"
namespace = "production"
database = "analytics"

# Optional authentication
username = "admin"
password = "secure_password"

connection_timeout_secs = 30
request_timeout_secs = 30

# Global defaults
batch_size = 100
flush_interval_ms = 1000

#######################
# User Events Topic (JSON Schema with validation)
#######################
[[surrealdb.topic_mappings]]
topic = "/events/user"
subscription = "surrealdb-user-events"
subscription_type = "Shared"
table_name = "user_events"
expected_schema_subject = "user-events-v1"  # Schema validation enabled
storage_mode = "Document"  # Regular document storage for user events

include_danube_metadata = true
batch_size = 200  # Higher batch for high-volume topic
flush_interval_ms = 500  # Faster flush for real-time analytics

#######################
# IoT Sensor Data Topic (JSON Schema with validation)
#######################
[[surrealdb.topic_mappings]]
topic = "/iot/sensors"
subscription = "surrealdb-iot-data"
subscription_type = "Shared"
table_name = "sensor_readings"
expected_schema_subject = "sensor-readings-v1"  # Schema validation enabled
storage_mode = "TimeSeries"  # Time-series mode for IoT sensor data

# Auto-generate IDs for time-series data
include_danube_metadata = true
batch_size = 500  # Larger batch for IoT streams
flush_interval_ms = 2000  # Less frequent flush to reduce write load

#######################
# System Logs Topic (String Schema - no validation)
#######################
[[surrealdb.topic_mappings]]
topic = "/system/logs"
subscription = "surrealdb-logs"
subscription_type = "Exclusive"
table_name = "system_logs"
# expected_schema_subject not set - no validation (backward compatible)
storage_mode = "TimeSeries"  # Time-series mode for log data

include_danube_metadata = true
batch_size = 50  # Small batch for critical logs
flush_interval_ms = 100  # Fast flush for real-time monitoring

#######################
# Application Metrics Topic (JSON Schema)
#######################
[[surrealdb.topic_mappings]]
topic = "/metrics/counters"
subscription = "surrealdb-metrics"
subscription_type = "Shared"
table_name = "metric_counters"
expected_schema_subject = "metrics-v1"  # Schema validation enabled
storage_mode = "TimeSeries"  # Time-series mode for metrics

include_danube_metadata = true
batch_size = 100
flush_interval_ms = 1000

#######################
# Binary Data Topic (Bytes Schema)
#######################
[[surrealdb.topic_mappings]]
topic = "/data/binary"
subscription = "surrealdb-binary"
subscription_type = "Shared"
table_name = "binary_data"
# expected_schema_subject not set - no validation for binary data
storage_mode = "Document"  # Regular document storage for binary data

include_danube_metadata = false  # Keep records clean
batch_size = 50
flush_interval_ms = 2000

#######################
# E-commerce Orders Topic (JSON Schema with validation)
#######################
[[surrealdb.topic_mappings]]
topic = "/orders/created"
subscription = "surrealdb-orders"
subscription_type = "Exclusive"
table_name = "orders"
expected_schema_subject = "orders-v1"  # Schema validation for transactional data
storage_mode = "Document"  # Regular document storage for transactional data

include_danube_metadata = false  # Clean records for API responses
batch_size = 20  # Small batch for transactional consistency
flush_interval_ms = 100  # Fast flush for order processing
