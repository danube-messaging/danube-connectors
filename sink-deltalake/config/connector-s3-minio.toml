# Delta Lake Sink Connector - S3/MinIO Configuration Example
#
# This example shows how to stream events from Danube to Delta Lake tables
# stored in S3 or MinIO (S3-compatible storage).

connector_name = "deltalake-sink-s3"
danube_service_url = "http://localhost:6650"

[deltalake]
# Storage backend
storage_backend = "s3"

# S3 Configuration
s3_region = "us-east-1"

# MinIO endpoint (comment out for real AWS S3)
s3_endpoint = "http://localhost:9000"
s3_allow_http = true

# AWS credentials from environment:
# - AWS_ACCESS_KEY_ID
# - AWS_SECRET_ACCESS_KEY

# Global batch settings (can be overridden per topic)
batch_size = 100           # Flush after 100 messages
flush_interval_ms = 3000    # OR flush after 3 seconds (whichever comes first)

#######################
# Payment Events Topic
#######################
[[deltalake.topic_mappings]]
topic = "/events/payments"
subscription = "deltalake-payments"
delta_table_path = "s3://my-bucket/tables/payments"
write_mode = "append"
include_danube_metadata = true

# Schema validation (schema already exists on topic via producer/admin)
expected_schema_subject = "payment-events-v1"

# Field mappings: JSON path → Delta Lake column
field_mappings = [
    { json_path = "payment_id", column = "payment_id", data_type = "Utf8", nullable = false },
    { json_path = "user_id", column = "user_id", data_type = "Utf8", nullable = false },
    { json_path = "amount", column = "amount", data_type = "Float64", nullable = false },
    { json_path = "currency", column = "currency", data_type = "Utf8", nullable = false },
    { json_path = "status", column = "status", data_type = "Utf8", nullable = false },
    { json_path = "created_at", column = "created_at", data_type = "Timestamp", nullable = false },
]

#######################
# User Events Topic
#######################
[[deltalake.topic_mappings]]
topic = "/events/users"
subscription = "deltalake-users"
delta_table_path = "s3://my-bucket/tables/users"
write_mode = "append"
include_danube_metadata = false

# Schema validation (schema already exists on topic via producer/admin)
expected_schema_subject = "user-events-v1"

# Higher batch size for high-volume topic
batch_size = 2000

# Field mappings: JSON path → Delta Lake column
field_mappings = [
    { json_path = "user_id", column = "user_id", data_type = "Utf8", nullable = false },
    { json_path = "email", column = "email", data_type = "Utf8", nullable = false },
    { json_path = "name", column = "name", data_type = "Utf8", nullable = true },
    { json_path = "age", column = "age", data_type = "Int32", nullable = true },
    { json_path = "is_active", column = "is_active", data_type = "Boolean", nullable = false },
    { json_path = "signup_date", column = "signup_date", data_type = "Timestamp", nullable = false },
]
